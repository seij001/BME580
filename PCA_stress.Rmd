---
title: "PCA Demo"
output: html_notebook
---

Copied frm demo in class, use this analysis on the stress data

```{r setup, include=FALSE}
library(factoextra)
library(tidyverse)
library(corrplot)
```

First let's take a look at our dataset

```{r}
data = read.csv("stress_all_sensor.csv")
dim(data)
head(data, 10)


data = subset(data, select = -c(X,Timestamp) )

```
```{r}

data$Stress_level <- replace(data$Stress_level,data$Stress_level == 'na',NA)
data =drop_na(data)

data$Stress_level = factor(data$Stress_level, levels = c(0,1,2))
levels(data$Stress_level) <- c("No Stress", "Low Stress", "High Stress")
summary(data)
```

We can get an idea of how correlated this variables are to start using a correlation matrix (like we did in the ggplot demo)
```{r}

cor = cor(data %>% 
            select(-c(Stress_level,Date,Time)))
corplot = corrplot(cor, method = "number", tl.cex = .6, number.cex = .8)
```


When performing PCA, it is important to standardize the variables to have mean zero and standard deviation one. Let's see how our unscaled and scaled data will differ during PCA.

```{r}
ivs = data %>% select(-c(Stress_level,Date,Time))
pr_unscale = prcomp(ivs)
pr_scale = prcomp(ivs, scale=TRUE) # Note: output is a list, not a dataframe
# scale argument centers and scales
```

prcomp() provides us with a values:
```{r}
names(pr_scale)
```
The x matrix contains the principal component scores for each observations
```{r}
dim(pr_scale$x)

pr_scale$x
# If you were to use the principal component scores as inputs to a model, this is
# the matrix you would want to use.
```


The rotation matrix provides the principal component loadings; each column of pr.out$rotation contains the corresponding principal component loading vector or the degree to which the feature contribute to the principal component

```{r}
pr_scale$rotation
```

Recall that the purpose of PCA is to create new, orthogonal features which are linear combinations of the original features with the goal of maximizing variance. We can visually how much of this variance is explained using a scree plot (We'll use the factoextra package to make ours)
```{r}
fviz_eig(pr_scale, addlabels = T, ncp = 16)
fviz_eig(pr_unscale, addlabels = T, ncp = 16) # Why does the first PC of our unscaled data describe so much more variance than in the scaled data? Features with larger values appear to contribute more to the variance within the data compared to the smaller valued features when unscaled.

# Our loadings tell us that features with larger measurement (such as baseline.value) scales tend to contribute more to the PCs than features with smaller values ranges
pr_unscale$rotation
```
We can also looks at these in tabular form
```{r}
get_eig(pr_scale)
```


We can also visualize our first two PCs (which explain 54% of our cumulative variance) using a biplot. If you wished to visualize the first 3 principal components, you could create a 3D visualization with the plotly package.

To create our biplot, we'll use the factoextra package
```{r}
# as.POSIXct(data$Timestamp, origin="1970-01-01")
```


```{r}
fviz_pca_biplot(pr_scale)
# We can observe some clusters, for example, the observations on the far left,
# and a cluster between those and the main set of observations in the middle
```
If we know our class labels, we can actually take this visualization one step further 
```{r}
fviz_pca_biplot(pr_scale, geom="point", habillage=data$Stress_level) + 
  theme(text=element_text(family="Times New Roman", face="bold", size=12))  +ggtitle("PCA - Biplot across Stress Level Groups")

```
```{r}
ggsave(path = './',filename='PCA.png', width = 8, height = 6, device='png', dpi=300)

```

We can also visualize this data without the PCs
```{r}
# Easier data visualization using factoextra
fviz_pca_ind(pr_scale,
             col.ind = 'coord',
             habillage = data$Stress_level)

```


```{r}
library(dplyr)
trainingDF = read.csv('data_train.csv')
trainingDF = trainingDF %>% dplyr::select(c(sID,Stress_level))
ggplot(data=trainingDF, aes(x=sID, fill=Stress_level)) +
  geom_bar()

```
```{r}
testingDF = read.csv('data_test.csv')
testingDF = testingDF %>% dplyr::select(c(sID,Stress_level))
ggplot(data=testingDF, aes(x=sID, fill=Stress_level)) +
  geom_bar()
```