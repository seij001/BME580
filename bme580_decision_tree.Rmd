---
title: "Decision Tree Models"
author: "Seijung Kim, some parts of code adapted from 'DT_RF_Demo' by Zachary Quinn"
date: "4/9/2023"
output: pdf_document
---

```{r setup, include=FALSE}
library(MASS) # includes two pima datasets
library(dplyr)
library(corrplot)
library(tree)
library(randomForest)
library(stringr)
library(caret)
library(ggplot2)
library(gbm)
library(ROCR)
set.seed(2022) # used to guarantee same random values are produced when rerunning code
```

```{r}
# Load data
Data_train <- read.csv("data_train.csv")
head(Data_train, 10)

Data_test <- read.csv("data_test.csv")
head(Data_test, 10)
```

```{r}
# Yes = 1 & 2
# No = 0
# Unknown = Missing

# Before running the decision tree, need to make the stress level binary
# Make two dummy variables that represent this discrimination: 
# (a)(Yes stress + unknown) vs. no stress 
# (b) Yes stress vs. (no stress + unknown).
# Have these in separate dataframes


# Remove missing values in the training and test sets
Data_train <- Data_train %>% filter(Stress_level != "Missing")
Data_test <- Data_test %>% filter(Stress_level != "Missing")

# Create Yes(1) and No(0) stress categories
# By replace all 2 with 1
Data_train$Stress_level <- str_replace(Data_train$Stress_level, "2", "1")
Data_test$Stress_level <- str_replace(Data_test$Stress_level, "2", "1")

Data_train # 43,716 rows
Data_test # 13,388 rows
```

```{r}
# Remove columns: X, Timestamp, Acc1_Mean, Acc1_Std, Acc2_Mean, Acc2_Std, Acc3_Mean, Acc3_Std, sID, date, time
Train <- subset(Data_train, select = -c(X, Timestamp, Acc1_Mean, Acc1_Std, Acc2_Mean, Acc2_Std,
                                Acc3_Mean, Acc3_Std, sID, date, time) )
Test <- subset(Data_test, select = -c(X, Timestamp, Acc1_Mean, Acc1_Std, Acc2_Mean, Acc2_Std,
                                Acc3_Mean, Acc3_Std, sID, date, time) )

# Convert data types: Stress_level to factor
Train$Stress_level <- as.factor(Train$Stress_level)
Test$Stress_level <- as.factor(Test$Stress_level)

Train
Test

```

```{r}
ncol(Train)

# We have 7 predictors (columns excluding response)
```




```{r}
# Random Forests (version with no k-fold cross validation)

# mtry = sqrt(p) for classification
# ntree is default 500 (number of trees to grow), can increase to something like 1000
# mtry is number of variables in subset considered in each split
# got this: Warning: invalid mtry: reset to within valid range mtry = 8 (BUT WHY?)
rf.pima = randomForest(Stress_level~., data = Train, mtry = sqrt(7), ntree = 500) # 500 is default
rf.pima


rfPreds = predict(rf.pima, Test)
table(Predicted = rfPreds, Actual = Test$Stress_level)

plot(rf.pima)  # find min error rate and return number of trees used in min error rate
which.min(rf.pima$err.rate)

oob.err = double(7) # out of bag error, mtry = 8 -> OOB error = 5.53%
test.err = double(7)

# Problematic: mtree=678 is tuning model with knowledge of test data
# Need to make a second test data set
# Get all data together and run k-fold cross validation
# If 2-fold then 2 train & test sets and I can average error in between them)
# Or have train-validation-test and test set is only used for final test
for (mtry  in 1:7){
  fit = randomForest(Stress_level~., data = Train, mtry = mtry, ntree=500)
  oob.err[mtry] = fit$err.rate[500]
  pred = predict(fit, Test)
  test.err[mtry]= length(Test$Stress_level) - sum(ifelse(pred==Test$Stress_level, 1, 0))
}

# After each iter, stepFactor determines how much mtry is increased
# improve indicates the amount that oob error must decrease for the mtry search to continue
tuner = tuneRF(Train[1:7], Train$Stress_level, # specify train and test data
               stepFactor = .5, # how much you increase mtry
               plot=T,
               ntreeTry = 500,
               improve = 0.1) # oob error must decrease at least 0.1 for mtry search to continue

plot(oob.err)
plot(test.err)
```



```{r}
# Apply K-fold cross validation to Random Forest (to "data_train.csv")
folds <-createFolds(y=Train$Stress_level, k=5, 
                    list=TRUE, returnTrain=TRUE) # or return test
sapply(folds, length)

acc_sum = 0
auc_sum = 0

for (fold in folds){
  # Divide train and test set
  k = as.integer(sqrt(length(fold)))
  training_k = Train[fold,]
  testing_k = Train[-fold,]
  
  # Train model
  rf.pima = randomForest(Stress_level~., data = training_k, mtry = sqrt(7), ntree = 500)

  rfPreds = predict(rf.pima, testing_k)
  pred = prediction(as.numeric(rfPreds),as.numeric(testing_k$Stress_level))
  
  plot(rf.pima)  # find min error rate and return number of trees used in min error rate
  which.min(rf.pima$err.rate)
  oob.err = double(7)
  test.err = double(7)
  
  for (mtry  in 1:7){
  fit = randomForest(Stress_level~., data = training_k, mtry = mtry, ntree=500)
  oob.err[mtry] = fit$err.rate[500]
  pred = predict(fit, testing_k)
  test.err[mtry]= length(testing_k$Stress_level) - sum(ifelse(pred==testing_k$Stress_level, 1, 0))
  # changed code to get observations misclassified instead of correctly classified
  }

  # After each iter, stepFactor determines how much mtry is increased
  # improve indicates the amount that oob error must decrease for the mtry search to continue
  tuner = tuneRF(training_k[1:7], training_k$Stress_level, # specify train and test data
                stepFactor = .5, # how much you increase mtry
                plot=T,
                ntreeTry = 500,
                improve = 0.1) # oob error must decrease at least 0.1 for mtry search to continue
  plot(oob.err)
  plot(test.err)
  
  # Get AUC
  pred = prediction(as.numeric(rfPreds),as.numeric(testing_k$Stress_level))
  auc_ROCR = performance(pred, measure = "auc")
  auc_ROCR =  auc_ROCR@y.values[[1]]
  
  # Get accuracy
  tab = table(Predicted = rfPreds, Actual = testing_k$Stress_level)
  accuracy = (tab[0,0] + tab[1,1])/sum(tab)
  
  acc_sum  = acc_sum + accuracy
  auc_sum = auc_sum + auc_ROCR
}
print(acc_sum/5)
print(auc_sum/5)

```

```{r}
# Looking at the test.err graphs for all 5 runs,
# Minimum # of misclassification that mtry = 5, 6, 5, 6, 5
```


```{r}
# Analyze accuracy for Random Forest (if tuned well, can have much less overfitting than regular decision tree)

optRf = randomForest(Stress_level~., data = Train, mtry = 5, ntree = 500)
optPreds = predict(optRf, Test)
opt_rf_acc = sum(ifelse(optPreds==Test$Stress_level, 1, 0)) / nrow(Test)
# Make confusion matrix
table(Predicted = optPreds, Actual = Test$Stress_level)

varImpPlot(optRf,
           sort = T,
           n.var=7,
           main = 'Top Variables')

# Determine variable importance

# For classification, use GINI (a measure of node impurity) 
importance(optRf)

hist(treesize(optRf),
     main = "No. of Nodes for the Trees",
     col = "green")

# GINI is a measure of how each variable contributes to the homogeneity of the nodes and leaves in the resulting random forest. The higher the value of mean decrease accuracy or mean decrease Gini score, the higher the importance of the variable in the model. (https://plos.figshare.com/articles/figure/Variable_importance_plot_mean_decrease_accuracy_and_mean_decrease_Gini_/12060105/1#:~:text=The%20mean%20decrease%20in%20Gini,the%20variable%20in%20the%20model.)
```

```{r}
# Calculate accuracy
# Accuracy = (true positive + true negative) / total cases = # guessed correctly/ # total data
Accuracy = (10334 + 1091) / 13388
Accuracy # 0.8534509
  
# Calculate missclassificaiton rate
# Misclassification rate = (false positive + false negative) / total cases
Miss = 1 - Accuracy
Miss # 0.1465491

# Find AUC
pred = prediction(as.numeric(optPreds),as.numeric(Test$Stress_level))

auc_ROCR = performance(pred, measure = "auc")
auc_ROCR =  auc_ROCR@y.values[[1]]
  
print(auc_ROCR)

# Sensitivity = true positive rate = TP/P_total = TP/(TP+FN)
Sensitivity = 10334/(10334+418)
Sensitivity
```



```{r}
# Calculate relative importance of sensors
results = importance(optRf)

# Combine EDA importance
EDA_sum = results['EDA_Mean',] + results['EDA_Std',] + results['EDA_Num_Peaks',]
HR_sum = results['HR_Mean',] + results['HR_Std',]
Temp_sum = results['Temp_Mean',] + results['Temp_Std',]

# Convert to relative importance
total = EDA_sum + HR_sum + Temp_sum
EDA_im = EDA_sum/total
EDA_im
HR_im = HR_sum/total
HR_im
Temp_im = Temp_sum/total
Temp_im
```




```{r}
# Analyze accuracy for Random Forest (if tuned well, can have much less overfitting than regular decision tree)

optRf = randomForest(Stress_level~., data = Train, mtry = 6, ntree = 500)
optPreds = predict(optRf, Test)
opt_rf_acc = sum(ifelse(optPreds==Test$Stress_level, 1, 0)) / nrow(Test)
# Make confusion matrix
table(Predicted = optPreds, Actual = Test$Stress_level)

varImpPlot(optRf,
           sort = T,
           n.var=7,
           main = 'Top Variables')

# Determine variable importance

# For classification, use GINI (a measure of node impurity) 
importance(optRf)

hist(treesize(optRf),
     main = "No. of Nodes for the Trees",
     col = "green")

# GINI is a measure of how each variable contributes to the homogeneity of the nodes and leaves in the resulting random forest. The higher the value of mean decrease accuracy or mean decrease Gini score, the higher the importance of the variable in the model. (https://plos.figshare.com/articles/figure/Variable_importance_plot_mean_decrease_accuracy_and_mean_decrease_Gini_/12060105/1#:~:text=The%20mean%20decrease%20in%20Gini,the%20variable%20in%20the%20model.)
```
